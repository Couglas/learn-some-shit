# MySQL的基本架构

客户端-连接器-分析器-优化器-执行器-存储引擎

# redolog

redolog是InnoDB引擎特有的日志，属于物理日志，记录的是在某个数据页上做了什么修改。主要用来保证事务的持久性，即数据库崩溃后可以恢复

WAL技术，先写日志，再写磁盘。具体来说，当一条记录需要更新时，InnoDO引擎先把记录写到redo log中，并更新内存，此时更新就算完成。InnoDB引擎在合适的时候将redo log的记录写到磁盘里。

redo log的大小是固定的，采用环形日志。比如可以配置一组4个文件，每个文件1G。从头开始写，写到末尾又回到开头写。writepos是当前记录位置，checkpoint是当前要擦除的位置，擦除记录前要把记录更新到数据文件。两者之间是空着的，可以用来记录，当writepos追上checkpoint代表写满了，此时不能执行新的更新，得先擦除一部分，推进checkpoint

innodb_flush_log_at_trx_commit=1，表示每次事务的redolog都直接持久化到磁盘

# binlog

binlog（归档日志）是在Server层，属于逻辑日志，记录的是语句的原始逻辑，比如给某一行数据的某个字段加1。主要用于逻辑恢复，确保数据完整性，即数据复制、主从同步和数据恢复等

binlog采用追加写方式，日志文件到达一定大小后会切换下一个，不会覆盖之前的

sync_binlog=1，表示每次事务的binlog都持久化磁盘

# undolog

回滚日志，记录回滚操作，即与变更相反的操作记录。当系统没有比回滚日志更早的视图read-view时，回滚日志会被删掉

# 更新一条数据的流程

1. 执行器先找引擎取id=2的数据。id是主键，引擎用树搜索找到。如果这一行的数据就在内存中，直接返回给执行器，否则从磁盘读如入内存后再返回
2. 执行器拿到引擎的给的数据，把值+1，得到新的，再调引擎接口写入这行数据
3. 引擎将这行数据更新到内存，同时将更新操作记录到redolog，此时redolog处于prepare状态，然后告知执行器执行完成了，随时可以提交事务
4. 执行器生成这个操作的binlog，并把binlog写入磁盘
5. 执行器调用引擎的提交事务接口，引擎把刚才的redolog改成commit状态，更新完成

redolog的写入拆成了两个步骤，这就是两阶段提交。为了保证日后恢复数据的时候数据库的状态和恢复出来的数据库的状态一致。redolog 和 binlog都可用于表示事务提交状态，两阶段提交就是为了让这两个状态保持逻辑上一致。

# 事务隔离

事务的核心特性：原子性、一致性、隔离性、持久性

MySQL的隔离级别：未提交读、已提交读、可重复读、串行化

分别解决了：脏读、不可重复读、幻读

事务启动有两种方式：

	1. begin/start transaction，这种启动方式一致性视图是在执行第一个快照读语句时创建的
	1. start transaction with sonsistent snapshot，这种

在MySQL的实现，采用MVVC多版本并发控制，未提交读基本没做处理，直接返回记录的最新值；已提交读和可重复读是创建了一个视图，访问的时候以视图的逻辑结果为准，区别是，已提交读是在SQL开始时创建一个视图（每次查询时都会重新创建一个新的视图，获取当前数据库中最新的提交数据，因此可能导致多次查询查到不同的数据），而可重复读是在事务启动时创建的（创建该事务开始的所有快照数据，后面查询都基于这个视图），在整个事务期间都使用这个视图；串行化则是通过加锁，使事务之间串行执行

MySQL中，有两种视图的概念：

1. view，是一个用于查询语句定义的虚拟表，调用的时候执行查询语句并生成结果。create view用来生成view，查询则和查询表一样
2. 一致性读视图，consitent read view，用于支持RC和RR隔离级别的实现

在可重复读的级别下，事务启动时创建了一个快照，基于整个库的一个快照，那么这个快照是如何创建的？InnoDB里面每个事务都有一个唯一的事务ID，transaction id，在事务开始时向InnoDB的事务系统申请的，按申请顺序严格递增

而每行数据也有多个版本，每次事务更新数据的时候，都会生成一个新的数据版本，并且把此事务的transaction id赋值给这个数据版本的事务id，即row trx_id。同时，旧版本的数据保留，并且在新的数据版本中，能够有信息可以直接拿到它（通过undolog逆向处理，获得对应版本的数据）。

按照可重复读的定义，事务启动时，能够看到所有已提交的事务结果，之后事务执行期间，其他事务更新对它不可见。因此，事务在启动的时候，以它的启动的时刻为准，如果某个数据版本在它生成之前生成的就可见，如果在它之后生成的就不可见，除此，自己更新的数据，也可见，无关之前还是之后生成。

在实现上，InnoDB为每个事务构造一个数组，存储事务启动瞬间，当前正在活跃的所有事务ID（启动了但没提交的事务）。数组里面事务ID的最小值叫低水位，当前系统重已创建的事务ID的最大值+1记为高水位，这样，这个视图数组和高水位就组成了当前事务的一致性视图。可见性就是基于数据的row trx_id和一致性视图对比结果得到的。通过数组，可以把row trx_id分成以下几种情况：已提交事务：低水位：未提交事务：高水位：未开始事务

1. 如果落在已提交事务部分，表示这个版本是已提交的事务或当前事务自己生成的，这个数据可见
2. 如果落在未开始事务部分，表示这个版本是将来启动的事务生成，这个数据不可见
3. 如果落在未提交事务即低水位到高水位之间
   1. 如果row trx_id在数组中，表示这个版本是还没提交的事务生成的，不可见
   2. 如果row trx_id不在数组中，表示这个版本是提交了的事务生成的，可见

通过这个数组，InnoDB利用了所有数据都有多个版本的特性，实现了秒级创建快照的能力。一个事务启动后创建的一致性视图，无论这个事务是什么时候查询，不管是否数据是否修改过，它查的结果都是一致的，所以称之为一致性读

简化上述的表述，一个数据版本，对于一个事务视图来说，除了自己的更新总是可见，有三种情况：

1. 版本未提交，不可见
2. 版本提交，在视图创建之后创建的，不可见
3. 版本提交，在视图创建之前创建的，可见

上面说的都是查询的情况，更新数据update的时候，则有所不同。因为如果更新时，也按可见性取历史版本的数据计算，则其他事务的更新就丢失了。因此，更新数据都是先读后写，这个读只能读当前值，也就是最新值，称为当前读。

除了update语句存在当前读，select加锁（给select语句加上lock in share mode，读锁（S锁，共享锁）或for update，写锁（X锁，排他锁））的话也是当前读。

一致性读，当前读，行锁之间有什么关联？一致性读依赖的是mvvc的多版本机制，通过数据的row trx_id保证可见性，选择历史版本数据读取；当前读实际上是由行锁来实现的，持有行锁的更新操作才能进行当前读，否则会被阻塞

可重复读的核心是一致性读，而事务更新数据的时候，只能用当前读，如果当前记录的行锁被其他事务占据，需要进入锁等待。读提交的逻辑和可重复读类似，主要区别如下：

- 可重复读在事务开始的时候创建一致性视图，之后事务里的其他查询都用这个一致性视图
- 读提交在每个语句执行前都会重新算一个新视图

可以通过transaction-isolation设置隔离级别



# 长事务

长事务意味着系统里存在很老的事务视图，由于这些事务随时可能访问数据库里的任何数据，所以在此事务提交之前，库里它可能遇到的回滚记录必须保留，导致占用大量存储空间，影响回滚段的大小。

长事务还占用锁资源，拖垮整个库

# 事务启动方式

1. 显示：begin或start transaction + commit/rollback
2. set autocommit=0，关闭线程的自动提交，例如select后事务启动，但是不会提交，直到主动commit或rollback或断开连接。set autocommit=1更推荐使用。

# 一天一备和一周一备

- 一天的好处是最长恢复时间更短，最坏的情况是需要应用一天的binlog
- 一周则最坏需要一周的binlog

# 索引

## 索引的方案选择

常见的索引结构有hash表、有序数组、二叉搜索树、跳表（redis中）、LSM树

hash表只适合等值查询，不适合范围查询

有序数组天然等值查询和范围查询，可以采用二分法查询。缺点是更新的时候老费劲了，需要移动大量数据。因此它只适用于静态存储引擎，即存储的数据不变

二叉搜索树，特点是父节点左子树所有节点的值小于父节点的值，右子树所有节点的值大于父节点的值，查询也是二分，不过需要维护树的平衡，比较费时。其次，二叉树有可能太高，写到磁盘中可能分到不同的数据块中，查询速率就慢。假设100万节点的平衡二叉树，树高20，一次查询访问20个数据块。机械硬盘随机读取一个块需要10ms寻址时间，20*10ms就是0.2s的时间，很慢。

因此，综上，MySQL采用的是N叉树，具体说是B+树，N取决数据块的大小。以InnoDB的正数字段索引为例，N差不多是1200。InnoDB的数据块默认16KB，每个节点存储子节点的指针、索引的值、数据的地址（除此之外还有其他元数据，页头、页尾、数据填充等），指针基于64位即8字节，索引的值正数的话就是int，4字节，一个节点就是12字节（实际上可能更大），一个块能存储(16*1024 )/12 =1,365.333 ，差不多就是1200。

![image-20250219151231661](/Users/a123456/Library/Application Support/typora-user-images/image-20250219151231661.png)

![2483114-20230702194522364-4559735](/Users/a123456/Downloads/2483114-20230702194522364-4559735.png)

![image-20250219151358613](/Users/a123456/Library/Application Support/typora-user-images/image-20250219151358613.png)

![image-20250219151424100](/Users/a123456/Library/Application Support/typora-user-images/image-20250219151424100.png)

当树高4时，可以存储1200^3个值，差不多17亿。考虑到树根的数据块总在内存中，因此查询10亿行表上的整数段索引最多访问磁盘3次（10^9 =1200^H => H = 2.9）。其实树的二层大概率也在内存中，这样访问磁盘的平均次数会更少

## 索引分类

> [!IMPORTANT]
>
> 数据库底层存储的核心基于数据模型的。每碰到一个新数据库，先关注它的数据模型，才能从理论上分析这个数据库的适用场景。

在Mysql中，索引是存储引擎实现的，没有统一的索引标准，不同的引擎的索引工作方式并不一样，哪怕索引类型相同，底层实现也可能不同

InnoDB的索引模型分为聚簇索引和非聚簇索引。聚簇索引的叶子节点存储的是记录数据，也叫主键索引，非聚簇索引叶子节点存储的是主键值，查到主键值之后还需要再查主键的索引树（回表），非聚簇索引也叫非主键索引或二级索引

索引维护也有一些需要注意的情况。当插入的主键id在已有主键id之间，且已有主键id所在的数据页已满，则根据B+树的算法，需要申请一个新数据页，将部分数据移动过去（页分裂），影响性能，影响数据页的利用率，原本在一页的数据分到两页中。另一种情况则是相邻两个页由于删除了数据，利用率较低之后，会进行合并。当这些情况比较多时，可能需要重建索引。

因此，一般建议建表语句里要有自增主键，不触发叶子结点的分裂。当然不排除业务逻辑字段做主键，往往不容易保证有序插入，写入成本较高。除了从性能考虑，从存储空间考虑，主键长度越小，普通索引的叶子节点就越小，占用空间也就越小，因为普通索引的叶子阶段存的是主键值

## 普通索引和唯一索引如何选择？

- 查询过程

  对于普通索引，查询到满足条件的第一个记录后，需要查找下一个记录，知道找到第一个不满足的记录；对于唯一索引，由于唯一性，找到第一个满足的记录后就停止检索

  由于InnoDB的数据是按数据也为单位存储，默认16kb，当读一条记录和下一条记录的时候大概率在一页上，多余的只有一次指针寻找和计算的区别，以整型字段来说，一个数据页可存放近千个key，因此这种概率基本忽略不计

- 更新过程

  在InnoDB中，当需要更新一个数据页时，如果页在内存中就直接更新，如果没在，为了不影响数据一致性，它会将这些更新操作存储在change buffer中（从change pool划分，通过参数innodb_change_buffer_max_size设置大小，=50表示最多占50%的空间），这样不需要从磁盘中读取，减少读磁盘，提升执行速度，而且change buffer还小于页的大小，避免占用内存，提升内存利用率。

  只将更新写入change buffer中不行，需要在合适时候也更新到页中才能保证数据的正确性。合适的时候包括：

  1. 下次查询需要访问该数据页时，将数据页读入内存，执行change buffer中与页相关的操作，得到最新的结果。这个过程叫做merge
  2. 后台线程会定期merge
  3. 数据库正常关闭时，也会执行merge

  除此以外，change buffer也会存储在数据库的系统表空间的磁盘中。

  通过上面change buffer的说明，可以知道，InnoDB在更新一条目标页不在内存中的记录时：

  - 唯一索引需要将数据页读入内存，判断是否冲突，然后更新，结束
  - 普通索引直接将更新记录写到change buffer中，结束

  普通索引更新比唯一索引少了一次随机IO的访问，提升会相当明显。不过，存在一个特殊情况，如果一个数据更新之后立即查询，会立即merge操作，则change buffer非但没有减少磁盘访问，还增加了change buffer维护的性能损耗，这样得不偿失。

  change buffer的主要目的将记录变更的缓存下来，因此一个页merge之前，change buffer的记录越多，收益越大。这就适合写多读少的业务，比如账单类，日志类的系统。

  change buffer和redo log（WAL机制）之间有什么联系吗？

  一个更新语句可能会涉及四个部分：内存、redo log（ib_log_fileX）、数据表空间（*.ibd）、系统表空间（ibdata)。具体的顺序如下：

  1. page1在内存中，直接更新内存
  2. page2不在内存中，在change buffer中记录更新操作
  3. 将1、2记录到redo log中

  后台还会将change buffer写入系统表空间、page1的内存写入数据表空间，这两个不影响更新的响应时间

  综上，page1 WAL之后读数据，不需要读盘、把redo log里的数据更新才返回，直接返回内存中的结果；page2 则需要将page2读入内存，应用change buffer的操作，生成正确版本才返回。即redo log节省随机写磁盘的IO消耗（改成顺序写），change buffer主要节省随机读磁盘的IO消耗

## 索引优化

- 索引覆盖

  查询的列就在索引树上，不用回表，减少树的搜索次数，显著提升查询性能

- 联合索引最左前缀

  联合索引的索引树的节点存储的是按定义的联合索引的顺序的字段，例如（name，age）的联合索引 ，存储的就是（"李四"，14）-> ("王五"，30)，查询like '李%'，锁定李四对应的主键id，然后向后遍历，知道不满足条件为止

- 索引下推（5.6之后引入）

  在索引遍历的过程中，对索引中包含的字段先做判断，直接过滤掉不满足的条件，减少回表次数。例如，查询name like '李%' and age > 30，先定位到李四对应的主键id，然后不是往后一个一个回表，而是再看age是否满足条件，不满足不回表，看下一个

# 锁

- 全局锁

  对数据库加锁，MySQL提供FTWRL命令，让整个库处于只读，加锁后，其他线程的数据更新、数据定义等语句会被阻塞。其使用场景是全库逻辑备份，把整个库的每个表select出来存成文本。

  但这很危险，如果在主库备份，则备份期间业务基本停摆，如果在从库备份，则备份期间从库不能执行主库同步的binlog，导致主从延迟。备份为什么加锁，不加锁备份得到的库不是一个逻辑时间点，视图并不一致。

  mysqldump是官方自带的逻辑备份工具，当使用参数-single-transaction时，导数据之前会启动一个事务，确保拿到一致性视图，由于MVVC的存在，这个过程中数据可以正常更新。FTWRL存在是InnoDB支持这个，不支持的只能用FTWRL。

  不推荐使用set global readonly=true，一是因为readonly被用作其他逻辑，比如判断主从库，修改global变量影响的面更广。二是异常处理机制不一样，FTWRL在异常时客户端断开连接，那么MySQL会自动释放全局锁，库可以复到正常状态，而设置readonly后，如果客户端异常，则数据库一直都是只读，风险太高

- 表锁

  一种是表锁，一种是元数据锁MDL。	

  表锁通过lock tables ... read/write。搭配unlock tables主动释放，或客户端断连自动释放。这个命令不只限制其他线程的读写，也限制当前线程的操作。InnoDB支持行锁，一般不使用表锁控制并发。

  MDL，不需显示调用，访问一个表时会自动加上。其作用是保证读写正确性。如一个查询遍历表中数据是，另一个线程对表结构做变更，删除一列，那么线程拿到的结果和之前的不一致。当对一个表增删改查时，加MDL读锁，做表结构变更时，加MDL写锁。读锁之间不互斥，读写、写写之间互斥。需要注意的一点是，当更新表结构是，需要判断是否有长事务正在执行，避免发生大量阻塞，甚至耗尽连接线程，使库挂掉。如果有长事务可以kill掉或者暂停DDL。如果是热点表，则在alter table语句中设置等待时间，如果在这个时间内获取到MDL写锁最好，不行也不阻塞业务语句，放弃重试。

- 行锁

  两阶段锁：在InnoDB事务中，行锁是在需要的时候才加上的，但不是不需要了就立刻释放，而是等待事务结束时才释放。通过这个特性，如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁往后放。因为如果事务锁多个行且冲突的锁放到前面，则锁在事务执行过程都持有，其他的事务都得等待锁，导致并发降低。

  事务在获取行锁时，不是一次性把所有行锁都获取到，而是执行到那一行才获取哪一行的锁，等到commit时才一起释放。

- 死锁和死锁检测

  当事务A和事务B都在等对方的行锁释放，就进入到了死锁状态，出现后有两种解决策略

  1. 直接进入等待，直到超时，通过innodb_lock_wait_timeout 设置，默认50s
  2. 发起死锁检测机制，发现后，主动回滚链中的一个事务，让其他事务执行，通过innodb_deadlock_detect =on开启，默认开启

  死锁检测有额外的负担，每一个事务被锁时，需要看它所有依赖的线程有没有被别人锁住，如此循环判断。假设1000个并发线程更新同一行，那么死锁检测就是1000*1000这个量级的，耗费大量的cpu资源。

  这种热点更新行导致的性能问题如何解决？

  1. 如果确保业务一定不会出现死锁，临时把死锁检测关掉。但是这个可能导致大量超时，业务有损
  2. 控制并发度：考虑将一行的逻辑改成多行减少锁冲突

# MySQL选错索引

选择索引是优化器的工作，找到一个最优的执行方案，用最小的代价去执行语句。在数据库中，扫描行数、是否使用临时表、是否排序等因素综合判断执行代价

扫描行数如何判断：MySQL真正执行语句之前，不能精确知道满足条件的记录有多少，只能根据统计信息来估计。这个统计信息就是索引的区分度，即一个索引上的不同值越多，则索引的区分度越好，也称为基数（可以通过 show index来查看）。

基数如何得到的呢：MySQL采用采样统计的方法，避免将所有行逐行统计而代价过高。InnoDB默认选择N个数据页，统计页上的不同值，得到平均值，乘以这个索引的页面数，得到索引的基数。数据表更新的时候，信息会不断变化，索引统计信息也会重新统计，条件是当变更数据行数超过1/M时。

MySQL有贷中存储索引统计的方式，通过innodb_stats_persistent 选择：

- on，表示统计信息持久化存储，N=20，M=10
- off，表示统计信息只存在内存中，N=8，M=16

对于一个具体语句来说，除了判断索引统计之外，优化器还要判断执行语句本身要扫描多少行。通过explain的row字段可以查看。如果没能准确判断扫描行数（数据表总在变化，事务删除数据之后若未提交，则数据并未真正删除，只是标识删除，统计时会加上这些），则可能导致选错索引。如果统计信息不对，可以通过analyze table t来重新统计。

## 索引选择异常和处理

1. force index 强制选择一个索引：MySQL根据词法分析的结果分析出可能使用的索引作为候选项，在候选项中一次判断每个索引扫描多少行，如果forece index 指定的索引就在其中，直接选择它，不评估其他索引执行的代价。不过这样不够通用，业务变更需要改代码
2. 考虑修改SQL，引导MySQL使用期望的索引
3. 某些场景下，建立更合适的索引给优化器做选择
4. 删掉误用的索引

# 怎么给字符串加索引

1. 直接创建完整索引，比较占用空间，导致每页数据变少，树高变高，增加IO次数
2. 创建前缀索引，节省空间，但是查询语句读数据次数变量，来回回表，增加扫描行数。除此之外，前缀索引还导致用不到索引覆盖，因为查出来的不是所有信息，还是需要回表。前缀多少是关键，如果数据样本较多，可以先查询一下，确定最短字符的区分度最多。
3. 倒序存储再创建前缀索引，用于绕过字符串本身前缀区分度不够的问题。查询的时候多一次函数的调用，新增一个字段，没法范围查询
4. 创建hash字段索引，查询性能稳定，没法范围查询，只能精确匹配，有额外的存储和计算消耗

# MySQL抖动

日常查询或更新时可能会遇到突然变慢的情况，给人感觉就是MySQL抖动了一下，具体是什么原因造成的？

InnoDB的WAL机制在处理更新语句的时候只做了写日志（redo log）这一个磁盘操作，更新内存写完redo log之后，就返回客户端，本次更新成功。在合适的时机将内存的redo log写入磁盘就是常说的flush。在flush之前，当内存数据页和磁盘数据页内容不一致的时候，这个内存页就是脏页，当flush到磁盘后，内存和磁盘的数据页一致，内存页就是干净页。

引起flush过程有以下几种情况：

1. redo log写满了，此时系统停止所有更新操作，推进checkpoint，给redo log留出空间可以继续写。推进的过程需要将之间的日志对应的所有脏页都刷入磁盘。
2. 内存不足，需要淘汰一些数据页，如果数据页是脏页，需要先flush。这里为什么不直接淘汰内存然后从磁盘读取数据页再用redo log操作该数据页。基于性能考虑，如果刷脏页一定写盘，就保证了每个数据页有两种状态：a. 在内存里的就是正确结果，直接返回。 b . 不在内存里，数据文件就是正确结果，读入内存后返回。这样的效率最高。
3. 系统认为空闲的时候，后台flush脏页
4. 关机的时候，flush所有脏页

后两种都是没有性能压力的。重点在于前两种刷盘时机。第一种情况下，系统就不能接受更新，需要避免，第二种是常态，InnoDB用buffer pool管理内存，池中的内存页要么没使用（没使用的情况比较少），要么使用了是干净页，要么使用了是脏页。

当要读入的数据页没有在内存中时，需要在buffer pool中申请一个，内存不足的情况下，只能把最久不使用的数据页淘汰，如果淘汰的是干净页，直接释放出来使用，如果是脏页，需要刷到磁盘后变成干净页再使用。出现一下情况时，会明细影响性能

1. 一个查询需要淘汰的脏页个数太多，导致查询响应时间明细边长
2. 日志写满，更新全部阻塞，写性能跌0，这种不能接受

InnoDB为此提供了控制刷脏页的策略来避免这些情况。首先，需要告诉InnoDB所在主机的IO能力，这样它才能知道刷脏页的时候可以刷多快，通过innodb_io_capacity来设置，告诉InnoDB的磁盘能力。这个值建议使用磁盘的IOPS，具体值可以通过fio工具来测试

```shell
 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
```

如果这个值设置的过低，刷脏页就会刷的慢，甚至比脏页生成的还慢，造成脏页积累，影响查询和更新性能

其次，InnoDB会按照一定的比例来刷脏页。具体考虑两个因素，一个是脏页比例（innodb_max_dirty_pages_pct）M，一个是redo log写盘速度（InnoDB每次写入日志都有一个序号，这个序号与checkpoint对应的需要之间的差值）N。它会根据M和N计算出两个值，取最大的记为R，然后按照innodb_io_capacity的值乘以R%控制刷脏页的速度。其中，脏页比例通过innodb_buffer_pool_pages_dirty/innodb_buffer_pool_pages_total得到的。

还有一个机制是，当准备刷一个脏页时，如果其旁边也是脏页，就会一起刷掉，一次类推，这样也会导致变慢。控制这个的参数是innodb_flush_neighbors，=1就是开启，=0就是关闭。这个存在的意义是可以减少很多随机IO，机械硬盘的随机IOPS一般只有几百，相同逻辑操作减少IO意味着系统性能大幅提升，所以机械硬盘建议开启。而固态硬盘IOPS比较高，建议关闭，减少SQL响应时间。

如果在配置一个内存大小为128G，innodb_io_capacity=20000的实例上，将redo log大小设置成1个100MB的文件，可能导致什么情况？

1. 性能下降：redo log太小，总是很快写满，导致频繁的日志切换，增加写入延迟，从而降低性能
2. 事务回滚增加：redo log空间不足，新事务无法记录，导致频繁回滚
3. 检查活动点增加：频繁的将脏页写入磁盘，增加I/O压力

正常情况下建议redo log设为4个1G大小的文件。出现这种情况的原因可能是配置错误，设置了不合理的值或者自动化脚本未做相关适配。为了避免应定期审查和测试配置，确保处在合理的范围。

# MySQL删除表数据空间为何不变

InnoDB的表包含两部分：表结构定义和数据。在8.0以前，表结构存在.frm后缀的文件中。8.0则允许吧表结构定义在系统数据表中，因为表定义占用空间小。

参数innodb_file_per_table（5.6之后默认是on）用来控制表数据存放的位置，off表示存放在系统共享表空间（.idata1文件），on表示每个表数据存储在.ibd文件中

由于InnoDB的底层使用B+树+页构建的结构，删除某个记录不会使文件缩小，只是标记该位置可复用，当整个页都删除掉的话，整个页被标记为可复用。不过记录的复用和数据页的复用还有不同，记录复用只能是记录范围还属于这个记录才能复用，而数据页可以分配给任意记录。使用delete删除整个表数据，只是把所有数据页都标记为可复用，磁盘上文件大小不会变小。

这些没有使用的空间就是空洞，除了删除会造成空洞之外，随机插入数据可能造成索引的数据页分裂。更新索引上的值其本质为删除旧值插入新值也会造成空洞。即经过大量删改的表都是可能存在空洞。

重建表可以解决这个问题。具体操作可以建一个新表，把旧表的数据逐行复制到新表，替换并删除旧表。这个操作当然不用自己做，InnoDB可以使用alter table a engine=InnoDB来重建表，MySQL会自动完整转存、交换并删除旧表。不过这个过程不是在线的，更新过程中如果有新数据写入会造成数据丢失。5.6版本开始引入了Online DDL，这个流程添加了一个逻辑，当生成临时文件时，对原表的操作会记录在一个日志文件row log中，临时文件生成后，将日志文件应用到临时文件，保证数据不会丢失。

alter语句在启动时会获取MDL写锁，不过这个写锁在真正拷贝数据的时候退化成读锁了，为了不阻塞增删改操作，但还是禁止其他线程对这个表同时做DDL。对于一个大表来说，Online DDL最耗时的过程就是拷贝的过程，这个期间可以接收增删改，相对整个过程来说，锁的时间非常短。扫描原表数据和构建临时文件比较消耗IO和CPU资源，因此线程服务还是要谨慎（可以使用gh-ost开源工具）

值得注意的是online和inplace概念容易混淆。online ddl创建的临时文件是在innodb内部创建出来的，对于sever陈总没有把数据挪动到临时表是一个原地操作（inplace），而非online得ddl是在server层创建的临时表。两者可以通过在alter语句后面加ALGORITHM=inplace/copy来选择。总结一下就是，DDL过程如果是Online的，就一定是inplace的，反之则未必，如果是inplace DDL，有可能不是Online的，8.0中的添加全文索引和空间索引是inplace的，但是会阻塞增删改，非Online

另外，alter table t engine = InnoDB是重建表recreate；analyze table t不是重建表，只是对索引信息做统计，没有修改数据，加了MDL锁；optimize table t等于recreate+analyze

# count(*)很慢怎么处理

MyISAM不支持事务，把count存了起来，直接返回比较快（不带条件），InnoDB由于MVVC的关系，不同事务读取不同的版本，导致查询出来的数据不一致，所以不能存count，只能遍历统计一下。不过，InnoDB也并不是遍历所有数据，而是扫描最小的索引树（主键索引树存数据，所以每页数据较少，页数更多，不够紧凑，普通索引树只存主键id，页数较少）。

- count(*)：不会把所有字段取出来，专门做了优化，不取值，按行累加
- count(1)：遍历整张表，但不取值，server层对于返回的每一行，放一个1，判断不可能为空，按行累加
- count(id)：遍历整个表，把每一行id都取出来，返回server，server拿到id判断不可能为空，按行累加
- count(字段)：遍历整张表，如果字段定义为not null，每行判断不为null，按行累加，如果允许null，取值然后判断，不是null才累加

实在接受不了这个count的时间，可以考虑以下方案：

1. 采用缓存，比如redis，插入一行，计数+1，删除一行，计数-1。同时查询总数和相应的记录的情况下，可能出现redis计数了，数据还没插入或数据插入了redis还没计数的情况，有可能不准确。
2. 使用单独的表计数：由于InnoDB支持事务和数据恢复，完美解决计数不准的问题，最起码在逻辑上是一致的。

# order by 如何工作

MySQL会给每个线程分配一块内存sort_buffer用于排序，如果sort_buffer_size大于要排序的数据量，排序就在内存中完成，如果小于则需要借助磁盘临时文件辅助排序（查看OPTIMIZER_TRACE的结果number_of_tmp_files来看是否使用了临时文件），如果文件有多个，mysql最后会把这多个文件通过归并排序合并成一个有序的大文件。

- 全字段排序

  字段不多，单行数据不大，采用这种排序方式。通常情况下，执行select a,b,c from t where a = '' order by c limit 100;（a上有索引）语句，流程如下：

  1. 初始化sort_buffer，确定放入a,b,c字段
  2. 从a索引找到第一个满足a=''条件的主键id
  3. 到主键id索引取出整行，取a,b,c三个字段的值，存入sort_buffer
  4. 从a索引取下一个记录的主键id
  5. 重复3、4直到a的值不满足查询条件为止
  6. 对sort_buffer按c进行排序
  7. 取排序结果的前100行返回

- rowid排序

  字段太多，内存中放下的行数就少，产生的临时文件就多，性能就差，MySQL就选择这个方案。通过max_length_for_sort_data来控制用于排序的行数据长度。如果超过这个值，就采用rowid排序。其执行流程如下：

  1. 初始化sort_buffer，确定放入id,c
  2. 从a索引中找到第一个满足a=''条件的主键id
  3. 从主键id索引取出整行，取id,c两个字段，存入sort_buffer中
  4. 从a索引中找到下一个记录的主键id
  5. 重复3,4直到a=''不满足为止
  6. 对sort_buffer中的数据按照c进行排序
  7. 遍历排序结果，取前1000行id，再从原表中查a,b,c三个字段返回客户端

rowid排序比全字段排序多访问了一次表的主键索引。MySQL如果担心排序内存太小影响排序效率，才会采用rowid排序算法，这样排序可以排更多行，但是需要回原表取数据。如果认为内存足够大，会优先选择全字段排序。提现了如果内存够，就多利用内存减少磁盘访问的设计思想

当然，不排序就最省时间。也就是建立相关的索引，索引就会默认排序。还可以考虑让语句命中覆盖索引，不用回表取数据，进而提高效率。

# 如何正确显示随机消息

1. order by rand()

   写法最简单，但是执行过程用到临时表，需要执行排序操作。对于InnoDB表执行全字段排序会减少磁盘访问一般会优先选择。对于内存表，回表只是简单根据数据行的为止，直接访问内存得到数据，不会访问磁盘，此时优先考虑的是排序的行越小越好，即选择rowid排序。

   执行流程如下：

   1. 创建临时表，临时表使用的memory引擎，没有索引
   2. 扫描原表全表，从中按主键顺序取出所有值，对于每个值，调用rand()函数生成一个0-1的随机小数，把值和小数存入临时表
   3. 按照临时表的小数字段排序，使用rowid排序，这里memory引擎不是索引组织表，rowid类似数据的下标
   4. 初始化sort_buffer
   5. 从临时表逐行取出数据，会扫描全表临时表
   6. 在sort_buffer中再排序
   7. 完成后取需要的前几位，然后一次到临时表中取对应的值返给客户端

   由此可知，经过了两次全表扫描和多次回表，因此性能较差。

   MySQL是如何定位一行数据的？对于有主键的InnoDB表来说，rowid就是主键id，没有主键id的InnoDB表来说，rowid是由系统自动生成的。

   并不是所有的临时表都是内存表。tmp_table_size限制了内存临时表的大小，默认16m，如果超过，则内存临时表就会转成磁盘临时表。磁盘临时表使用的默认引擎是InnoDB，通过internal_tmp_disk_storage_engine控制。当使用磁盘临时表的时候，对应的就是一个显示索引的InnoDB表的排序过程。

   MySQL5.6引入了一个新的排序算法：优先队列排序算法（可以查看OPTIMIZER_TRACE的filesort_priority_queue_optimization: chosen=true，不需要临时文件，number_of_tmp_files=0）。前一个排序把排序了大量不需要的数据，浪费了非常多的计算量，这个排序算法，可以控制只排指定数量的值。其流程如下：

   1. 对于排序的N行，先取M行，构成堆
   2. 取下一行，跟堆里面最大的比较，如果小于，去掉原来的，换成新的
   3. 重复2，直到所有都比较完成

   由此可见，只扫描了一次N行。不过这个算法不能应用所有情况，当M较多是，构造的堆会大于sort_buffer_size，这时只能使用归并排序算法，即需要用到临时文件

2. 随机排序方法

   1. 取表主键id的最大M和最小N，用随机函数生成两者之间的数X，取不小于X的第一个值。

      这个方法效率高，但是id中间有空洞，选择不同行的概率不一样，是伪随机

   2. 取表的整个行数C，取Y = floor(C * rand())，floor是取正数部分，再利用limit Y,1取一行。MySQL处理limit Y,1的做法是按顺序一个一个取出来，丢到前Y个，然后把下个记录作为返回结果，因此扫描Y+1行，再加上第一步扫描的C行，总共C+Y+1行，比1代价高，比order by rand小得多

# 为什么SQL语句逻辑相同但性能差异巨大

1. MySQL的B+树提供快速定位的能力，来源于同一层兄弟节点间的有序性。对索引字段做函数操作，可能破坏索引值的有序性，因此优化器就决定放弃走树搜索功能，转而走向遍历整个索引树，但是还是会比较主键索引和普通索引树那个成本低，然后选择低的那个。
2. 对于不影有序性的函数，如where id + 1 = 1000这个语句，优化器还是不能用id索引快速定位
3. 隐式类型转换。在MySQL中，字符串和数字比较的话，会将字符串转成数字。因此如果索引字段是字符串类型，条件传数字类型，会导致对索引字段加上转换函数，优化器会放弃走树搜索功能
4. 隐式字符编码转换。字符集不同，如utf8,utf8mb4，字符集utf8mb4是utf8的超集，当这两个类型字符串做比较的时候，MySQL会先把utf8字符串转成utf8mb4字符集，再做比较。当索引字段是utf8字符集的时候，就会导致索引失效。要解决的话，就改sql，是的转换函数加在参数上，即=右边。或者修改表的字符集。

# 只查一行数据为什么也很慢

- 长时间不返回。

  大概率表锁住了，一般首先执行一下show processlist，看看当前语句初审什么状态

  1. 等MDL锁，显示waiting for table metadata lock，表示现在有一个线程正在表上请求或者持有MDL写锁，阻塞了select语句。处理方式就是找到谁持有MDL锁，kill掉它，通过查询sys.schema_table_lock_waits表就可以找到阻塞的process_id
  2. 等flush，显示waiting for table flush，表示现在有一个线程要对表做flush操作。MySQL对表flush一般有两种：flush tables t with read lock 或 flush tables with read lock。后者表示关闭MySQL里所有打开的表。正常情况下这两个语句执行的很快，除非他们也被别的线程阻塞了
  3. 等行锁，select ... lock in share mode。这个语句是当前读，如果有事务在这行记录上持有一个写锁，就会阻塞。查询谁占用这个写锁，通过查询sys.innodb_lock_waits，结果blocking_pid就是造成阻塞的pid。kill query pid、kill pid，前者停止pid正在执行的语句，执行这个没用，因为占行锁的是update语句，该语句之前已经完成了，所以应执行后者，直接断开连接。

- 查询慢

  1. 没有索引，扫描行数过多。可以通过set long_query_time=N设置慢日志阈值，查询慢日志可以看到rowx_examined很多。需要注意的是，坏查询不一定是慢查询。
  2. 一种特殊情况普通查一行很慢，但是select ... lock in share mode比较快。线程A先启动一个事务，然后线程B开始执行update语句更新100w次，生成100万个回滚日志，后者查询是当前读直接读最新的数据，而普通查需要通过undo log计算100w次，才返回

# 幻读是什么，有什么问题

幻读是只一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入数据的。因此幻读是在当前读下才会出现。幻读转指新插入的行。

幻读会导致两个问题：

1. 语义上不对，假设线程A在T1时刻声明把指定范围的行锁住，不准别的事务进行读写，而幻读会导致这个语义被破坏。例如线程B在T2时刻插入一行该范围的数据并更新，不影响T1的声明，但是确实破坏了锁定该范围的行的语义
2. 数据一致性问题，假设线程A在T1时刻开启事务并加锁和更新某个范围的数据，线程B在T2时刻插入该范围的数据，线程A在T3时刻提交事务。这个逻辑下记录数据和binlog按顺序记录恢复的数据不一致。

而这两个问题，即使给所有行都加上锁，最多只能解决不可重复读的问题，无法解决幻读，因为加锁的时候幻读的这一行还不存在，无法加锁。为了解决这个问题，InnoDB只好引入新的锁，即间隙锁Gap Lock。这个锁的是索引之间的间隙，例如，6个记录就有7个间隙。当查询（select ... for update）某个范围时，就不止给符合的记录加上了行锁，同时还加上了相关的间隙锁，确保了无法再插入新的记录。

不过间隙锁和行锁不太一样，行锁只有读读兼容，读写、写写都互斥。间隙锁之间不存在冲突关系，冲突的是往间隙中间插入一个记录的操作。例如，可以同时给一个间隙加上间隙锁，它们都是保护这个间隙不允许插入值，所以它们不冲突。

间隙锁+行锁合称临键锁next-key lock，每个临键锁都是前开后闭区间，当执行查询（select ... for update）时，就形成了记录数+1个临键锁。

这两个锁的引入解决了幻读，但也带来了新的问题。并发情况下，任意锁住一行，如果这一行不存在就插入，如果存在就更新它的数据，这个逻辑会产生死锁。线程A在T1时刻select for update，线程B在T2时刻select for update，这两个都会加上相同的间隙锁，不会冲突，线程B在T3时刻往锁住的范围中插入被阻塞，线程A在T4时刻也往锁住的范围中插入也被阻塞，互相等待形成死锁。不过InnoDB的死锁检测能够发现这个死锁，让线程A直接报错返回。

间隙锁的引入导致同样的语句锁住更大的范围，影响了并发度。那么如何解决这个问题：间隙锁是在可重复读的隔离级别下才存在，把隔离级别设成读提交，就没有间隙锁。不过这样需要解决数据和日志不一致的问题，需要把binlog格式设置为row

# 只改一行数据为什么锁很多

原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。

原则 2：查找过程中访问到的对象才会加锁。

优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。

优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。





























​		